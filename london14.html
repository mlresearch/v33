<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title><span>PAC-Bayesian Collective Stability</span> | AISTATS 2014 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="{PAC-Bayesian Collective Stability}">

  <meta name="citation_author" content="London, Ben">

  <meta name="citation_author" content="Huang, Bert">

  <meta name="citation_author" content="Taskar, Ben">

  <meta name="citation_author" content="Getoor, Lise">

<meta name="citation_publication_date" content="2014">
<meta name="citation_conference_title" content="Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="585">
<meta name="citation_lastpage" content="594">
<meta name="citation_pdf_url" content="london14.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1><span>PAC-Bayesian Collective Stability</span></h1>

	<div id="authors">
	
		Ben London,
	
		Bert Huang,
	
		Ben Taskar,
	
		Lise Getoor
	</div>;
	<div id="info">
		JMLR W&amp;CP 33 
		
		: 
		585â€“594, 2014
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Recent results have shown that the generalization error of structured predictors decreases with both the number of examples and the size of each example, provided the data distribution has weak dependence and the predictor exhibits a smoothness property called collective stability. These results use an especially strong definition of collective stability that must hold uniformly over all inputs and all hypotheses in the class. We investigate whether weaker definitions of collective stability suffice. Using the PAC-Bayes framework, which is particularly amenable to our new definitions, we prove that generalization is indeed possible when uniform collective stability happens with high probability over draws of predictors (and inputs). We then derive a generalization bound for a class of structured predictors with variably convex inference, which suggests a novel learning objective that optimizes collective stability.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="london14.pdf">Download PDF</a></li>
			
			<li><a href="london14-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
