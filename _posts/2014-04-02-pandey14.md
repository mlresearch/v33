---
title: To go deep or wide in learning?
abstract: To achieve acceptable performance for AI tasks, one can either use sophisticated
  feature extraction methods as the first layer in a two-layered supervised learning
  model, or learn the features directly using a deep (multi-layered) model. While
  the first approach is very problem-specific, the second approach has computational
  overheads in learning multiple layers and fine-tuning of the model. In this paper,
  we propose an approach called wide learning based on arc-cosine kernels, that learns
  a single layer of infinite width. We propose exact and inexact learning strategies
  for wide learning and show that wide learning with single layer outperforms single
  layer as well as deep architectures of finite width for some benchmark datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: pandey14
month: 0
tex_title: "{To go deep or wide in learning?}"
firstpage: 724
lastpage: 732
page: 724-732
order: 724
cycles: false
author:
- given: Gaurav
  family: Pandey
- given: Ambedkar
  family: Dukkipati
date: 2014-04-02
address: Reykjavik, Iceland
publisher: PMLR
container-title: Proceedings of the Seventeenth International Conference on Artificial
  Intelligence and Statistics
volume: '33'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 4
  - 2
pdf: http://proceedings.mlr.press/v33/pandey14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
