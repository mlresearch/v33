---
title: "{Loopy Belief Propagation in the Presence of Determinism}"
abstract: It is well known that loopy Belief propagation (LBP) performs poorly on
  probabilistic graphical models (PGMs) with determinism. In this paper, we propose
  a new method for remedying this problem. The key idea in our method is finding a
  reparameterization of the graphical model such that LBP, when run on the reparameterization,
  is likely to have better convergence properties than LBP on the original graphical
  model. We propose several schemes for finding such reparameterizations, all of which
  leverage unique properties of zeros as well as research on LBP convergence done
  over the last decade. Our experimental evaluation on a variety of PGMs clearly demonstrates
  the promise of our method â€“ it often yields accuracy and convergence time improvements
  of an order of magnitude or more over LBP.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: smith14
month: 0
firstpage: 895
lastpage: 903
page: 895-903
sections: 
author:
- given: David
  family: Smith
- given: Vibhav
  family: Gogate
date: 2014-04-02
address: Reykjavik, Iceland
publisher: PMLR
container-title: Proceedings of the Seventeenth International Conference on Artificial
  Intelligence and Statistics
volume: '33'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 4
  - 2
pdf: http://proceedings.mlr.press/v33/smith14/smith14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
