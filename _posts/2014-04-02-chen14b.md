---
title: Efficient Low-Rank Stochastic Gradient Descent Methods for Solving Semidefinite
  Programs
abstract: We propose a low-rank stochastic gradient descent (LR-SGD) method for solving
  a class of semidefinite programming (SDP) problems. LR-SGD has clear computational
  advantages over the standard SGD peers as its iterative projection step (a SDP problem)
  can be solved in an efficient manner. Specifically, LR-SGD constructs a low-rank
  stochastic gradient  and computes an optimal solution to the projection step via
  analyzing the low-rank structure of its stochastic gradient. Moreover, our theoretical
  analysis shows the universal existence of arbitrary low-rank stochastic gradients
  which in turn validates the rationale of  the LR-SGD method. Since LR-SGD is a SGD
  based method, it achieves the optimal convergence rates of the standard SGD methods.
  The presented experimental results demonstrate the efficiency and effectiveness
  of the LR-SGD method.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: chen14b
month: 0
tex_title: "{Efficient Low-Rank Stochastic Gradient Descent Methods for Solving Semidefinite
  Programs}"
firstpage: 122
lastpage: 130
page: 122-130
sections: 
author:
- given: Jianhui
  family: Chen
- given: Tianbao
  family: Yang
- given: Shenghuo
  family: Zhu
date: 2014-04-02
address: Reykjavik, Iceland
publisher: PMLR
container-title: Proceedings of the Seventeenth International Conference on Artificial
  Intelligence and Statistics
volume: '33'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 4
  - 2
pdf: http://proceedings.mlr.press/v33/chen14b.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
