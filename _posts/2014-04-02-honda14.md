---
supplementary: Supplementary:honda14-supp.pdf
title: Optimality of Thompson Sampling for Gaussian Bandits Depends on Priors
abstract: In stochastic bandit problems, a Bayesian policy called Thompson sampling
  (TS) has recently attracted much attention for its excellent empirical performance.
  However, the theoretical analysis of this policy is difficult and its asymptotic
  optimality is only proved for one-parameter models. In this paper we discuss the
  optimality of TS for the model of normal distributions with unknown means and variances
  as one of the most fundamental examples of multiparameter models. First we prove
  that the expected regret of TS with the uniform prior achieves the theoretical bound,
  which is the first result to show that the asymptotic bound is achievable for the
  normal distribution model. Next we prove that TS with Jeffreys prior and reference
  prior cannot achieve the theoretical bound. Therefore choice of priors is important
  for TS and non-informative priors are sometimes risky in cases of multiparameter
  models.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: honda14
month: 0
tex_title: "{Optimality of Thompson Sampling for Gaussian Bandits Depends on Priors}"
firstpage: 375
lastpage: 383
page: 375-383
sections: 
author:
- given: Junya
  family: Honda
- given: Akimichi
  family: Takemura
date: 2014-04-02
address: Reykjavik, Iceland
publisher: PMLR
container-title: Proceedings of the Seventeenth International Conference on Artificial
  Intelligence and Statistics
volume: '33'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 4
  - 2
pdf: http://proceedings.mlr.press/v33/honda14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
